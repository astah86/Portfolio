{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003d3879",
   "metadata": {},
   "source": [
    "# Подготовка модели распознавания рукописных букв и цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd87151-6cf5-40aa-ab38-8e79056934a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import emnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Normalize\n",
    "from torchvision.datasets import EMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6215c2bb-455c-4ffb-8301-b02ee57d891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting (symbol):\n",
    "    if symbol < 10:\n",
    "        symbol = symbol + 48\n",
    "    elif symbol < 36:\n",
    "        symbol = symbol + 55\n",
    "    elif symbol < 38: \n",
    "        symbol = symbol + 61\n",
    "    elif symbol < 43: \n",
    "        symbol = symbol + 62\n",
    "    elif symbol < 44: \n",
    "        symbol = symbol + 67\n",
    "    elif symbol < 46: \n",
    "        symbol = symbol + 69\n",
    "    else:\n",
    "        symbol = symbol + 70\n",
    "\n",
    "    return chr(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "79400984-28ba-41a4-bf50-b8651a83dfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset EMNIST\n",
       "    Number of datapoints: 112800\n",
       "    Root location: data/\n",
       "    Split: Train"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = EMNIST('data/', 'balanced', download=False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "c7866108-ac21-40b3-8631-19eaadff104e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APBYLS5uVdoLeWURjc5RC20epx0pIbae4l8qCGSWT+6ikn8hVp9E1aNC76ZeKqjJJgYAD8qoV7j+z1qenPdarol3awtLPGJFkdQSyg4K8/7wr05tB8KfDHStS12a1jcyStKXaIFgSSwReOB2rzu9/aHs5Fmhi8KxSRMCoMkw5yO4214TcSie4klEaxh2LbF6D2FOs7uewvIrq2laKaJw6OpwQQcivW/FPxpi1/wBDof2F5L2WER3U0wGAwGNy89frXjtFFFFFf/Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABNklEQVR4AWNgGEqAEeRYJiaGPxBHA1kQAOYDJRnZXfW/7X7+hoFRWE5BGyz77+vuG78ZGFgYGNgkA82/cZw8wMBuaacIlfzC8fzdP5AZCoWf//17tkrCufrOrz//oOBpgAhYJws3GwMDv5KohYc00Bwo4BRhB0t+vPpejIFdodhOEsj/9/PLB6D8v+N73wBdw8DALNwZART+y8zA8Pvj4WP3r4Ise//2P8QM9vhXULte7Q5REmVlAQKYlxgYlE59+vfv////f9aGIGwFagSr+HTh7m8GoDH/Hz74CzEMiWQUtz7/Baj3z5oghHEwnf9fnulZ/5PhP5M2JAxg+qAqf53c+xnoAXCgwKTA/gRx/j/4e8Xs/769F1GkYa7792k3z791hz6iSIKjDGwQhwTD858II4ceCwA2nny20/o4QAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+u18N6N4HbS4r3xL4huY5pHI+xWUBZ0A4yzEYqLx/4IfwfqMD28rXOk3qCWyuWxl1wDg+4zXH1La273d3DbJgPK6ouemScV7Nr2k+EPhY9lpc/h8+INbuYi5kuHIjAbKgBR15Hpn3qf463MFt4Z8K6RHax2siIZWt42JEI2r8ozzjn9K8NpVYowZThgcg19DfDfxrpHj7W9OtvEmmwnXdNQvaXu7Alx/CR685x7VxHxnGuX/iA6nf+HZNMslcwxSvgmU+pIPtx7V5fRTo5ZIZFkidkdTlWU4IPsau6hreq6ssa6jqN1drH9wTSs4X6ZNUK//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABlElEQVR4AWNgIBcwImtkYRVn/fDuL1wISZJd3UXKgfvykp0/4bJwBnvU+S/ffv76fU6PAybGAmMwiyRI3DjwmS9QPWj9pf8wURjN7h2gxMnC2/3zznwRmBiCZmICspmCXvy6YwQVBAlAwb9/DOzS7CePM0o6QC2D28nAwC7JbhF3/psgIysvVDlckpk9MJ9fUMiKkYXpH8wsmCSTg0WS/M+Xjw6puLL//gyThdJiq579udtgrMDt9PjXPZiDoHJAR/5+lcDFwMBZ/+3rGQWYKIRmUuBl+nLlOwMDrw7rlwdfUSVBvN+f/zNweNoyPTr+HioJo4zu/HqVwMnsf+vPkzITWGzAXPv4HI9oNcPpWEXGb3bfLvyB6YHQzP7zv/59sf/Nv3+/TxbCdMCVcCjPf/H7779/f25FKcIF4QxGseAN3///2ePPAbMSLgViMJvc+fe+gI+FBRYbyMb/fXhOjitZ5vO/87uxpBQm5/Wff//6+W2XNMREVPOZ5QMttb/ch6UxVEkGBhZBgd9fkVIniqOI5wAAWOSGfyIdPNwAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APMfB3gy08QaRq+q6nqQ06zskCxSsBiSYglU5+n61zlhouqaortYaddXSp95oYmYD64FUSCpIIII6g0le3fD/wAN/wDCUfBe9sHnS2txq4muJ242RIqlj+Vc/q3xbv8ATbuDTfB/l6bolg2yFUQFrkLxukJHO7r+NVfi7bWk2taX4g063WG01mwjuSFAA83JDjA79K87r2zSdS/sz9mW/wAuQ1zdtAmxsHlhnP4A14nXovhzxL4X1LwimgeNPtuzT5TLYTWoy4VvvRn2yP1rg9Qmt7jUbiW0g+z2zyExRZzsXsM0n2+7/s/7B9pl+x+Z5vkbzs34xux0ziq9FFf/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABo0lEQVR4AWNgoAywsGDVzwgSVQhkWP8AqzQDA0vxx4+F2PSCxIQsOf/yYdMIlGSysTz26s1/BgZmXk7uD2+BDBgASrJbChya/vMvo6itj6Tcibb7f2FyIFrhzM96FgZG/fkvfv3883W9HztcEqiTlRfkZLH5mgzX9slbe8s/uASTBTkICBgVknXebZ9wm9e3TT0QLgmUUL35q56//tOteDGgCUpn/p6GagA6FayRPSD2e+nKV0CHPtv8Q5gVLAYhgDrXXv61Gqre+N5XJRTJf39/r4eJiK75XQwzF2gsHysD49slD6HKP1z+ZykIZTMxsNiLM/49fBjm9b+X3xvIAiVB3gPq5Gb5/37VW6hihn9HDkn6cTGw6AmBJP8/+srw/y8iRN/M/BITphlQqM/IALSbk5mB4R9MI5B5cFt41weeY/f/g4z9/pfh8SUk2T8TbvDLf1n8GBjRDIxy3H8PPEfoZGC4UW/AcGE30IVAY5kY/338jSz5c+t2hn8go4CSn39/uYpkKlAQLAOW/LPb+895VEmYMUC/skozPEUxFiZHAQ0A8P2RXEMvn+QAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+un8EeDZ/GGqTRm4Sz06zj8+9vJAdsMY6+24jOAfQ+lWNf1HwRNHJZaJod7bpFGRDqEtyWlmcd3Q/KFPoMEdfauQor1h9B8TWHwo0rSdE0nUZZdaaS/1FoLZm/dj5YoywHQgFtvXketeUujxSNHIpV1JVlYYII6g02rFje3WnXkd3ZXElvcRnKSxthl+hrtfij4g1S48a3tidTvXt7OOK0AeU/PsRQzEDjJbcT9a4InJyaKKs6hf3OqahcX95J5lzcOZJHwBlj7DgVWor/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA60lEQVR4AWNgIAkwcSow49KgtOrel9V6jNikGaNe/PvS23jFF4skZ/S37yBt/mWYkkzzvn2PBlnIyIspqfLq32pcjuE4/++uIqYWiEj8n8/FuORYb/yt58IlqfT1PE45pvk/TXDpY+C8904Sp6Taz/XsaJIscH4k4wwhXvmHD3/CRWAMJk6TF//fv/3582s+TAhIQ3QKdjrIsf1d9O7f1ctvkSQhTBYV28JfLehWIpQZf1NFcNBYTKteiqIJIbgsN9cwIXhQFkLk8j/ckv8eYMgxwHUyCuKR/PcIj+T325iScBFprEkVLo3JAABiPUMGIGQAdAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+u50XwhZ23gbUvFfiNJEt2TydLgD7WuJicbh/sr16c0238J2WkeAZ/EfiFZRcX2YNKtAdpY4B84n+6ORggZ/KuIrp/h/4Y/4S7xlY6W7Bbfd5twc4PlLywHB5xwK9ItoJ/il47MUtlLb+EPDysI7WKMqTGuQqhQCCzFRx6AiuI+J1/qmqa8l3qrW1uwTy7fTYZNxtIhnAYDhSfTOfbGK4er2kaxf6DqkOpaZcvb3cJyki/wAj6j2r2L4jePdctfAvhezt9ReO91KxW8v7iBfKchsbRlcYHLZ9cV4gzFmLMSSeST3pKK2LvxVrt9oVvolzqU0um2+BFA2MKB0GepA7A9Kx6K//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABYElEQVR4AWNgIB4wQpRCKRR9Qjk9CiABzokVTCgSII7xrQcuILnoLyeY0SXFbv1p4GJgYJr3dY8zuhxH/O8vekBBnjt/i9nQJLnqv3ypZ2Rg1D/8az0HmhxD9N2/65UYGBQXf7/ljy7Hc/7vN39mBsb6L7/j0TUq7vsLMpTZ/+v3xexoGhkTXn1frMjAoLL+7wV9NDkGpc//5osxMLCc+rvbGd3/zCF/vugDXary6ncICwMHL4pe3zvfGoDhqXf+93oepaKFrlBJFjBtIPt0838GxiD1D7szrHXjzqJIAoPF6BODdAkHc9Pj9cX3UExl8L3z99XNm/f+/XuxWg/dkwzMftdvfvv3/9sSMYzYAJrCrqre9ubfehVUAxG8+m+vgEGLHbCc/nuDFU0KERx8/6/8xSnJ8HbZP9ySX5+KyqPJwrjM+769vFSFsAUmDqH1553KA0YMDsCELQBwqAUKAwDdg3Hp9L7rjAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+rFhY3Gp6jbWFqnmXFzKsUa5xlmOAP1rrPijoOi+GfGT6RohkMdvBGJ98m/8AekZODj0I/HNcXRXs/wAAfC895qOp+JFhR3sYTFZCXKo07A8kjsAMHr96vO/Hej61onjC+t9fkil1GRvPklibKyb+cjgflgVzlFezD4j6do/w/wDDXhfwvcTR3czIdTmhRkdCx+dVPdiT1HYVkfH3/kqE3/XpD/I15hRSqxVgykgg5BHar2s61qPiDU5NR1S6e5upAA0jnsBgAegqhX//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABEElEQVR4AWNgIAUwCzDhVu431xmnJMv1f8/lYbLoZrCyM5x6gUtSTYLh3E+YJBrNcurfNz00MRiXUeXVnzXMMB4arXTq38sghBiqg4zkGR5eQEiisDgu/Pumz4gihOCY/Po3H5eNzPP//bYUwCGr8PXfv/uP53MgjEKwmEP+/P///9/fQrgQC5zFoF3DxPCfgYGRDy6E5JVANYb//5/CZYAMhKRSJgfDmzbfP0iyCMlYMYbfE9qUEAJIOpl0GRiezPmujVWSz4LhZ90rJGuQ7fx87OXiFQwMl/8h2Qn3yt8M5nd/GRge/kMyFy7J8A6sxRYhwMCAzAbJHvrD+AnJYFQmx646dlQRZJ68EDIPDxsAsbhIjS9OHFoAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APB7CwudU1C3sLKFprm4kEcUa9WYnAFemW/hbwD4Rtp4PGmpyX2sZB+x6YzHyfVWbG3d+NU/FHg3w5N4HHi/wpNfLarciCa1vNu6MHPzAjrzj1615vXo3wdtoU1/U9amwf7I06a6RSuSWC4BHoRVyL4f+GJb4WWteNVi166YZgit2dY5HP3XbueR6VduPC2peAPAXi7T/EMgS1vGhjsTGcieUEsCvoAAc8fjXkFbHhvxJf8AhbVRf6eYyzIY5YpV3JKh6qw7g12B+KWnYSRfAHhtbtORL9n43eu2ujvddm+Lfwz1N79Vj1nQW+1J5PCyREEEbc9h39h614pRRV3T9X1DSluVsLyW3F1EYZvLbG9D1B/KqVf/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABx0lEQVR4AWNgwAMYkeVYQJx//+BCyJIKgXxAuasXnv9EyMMU8tR/+vXr18+XZ7p9oVrgOoXl/eLk/71/z8AqwfLA6g1MB5jmqbr19euFGXHqqiZLvv8yQpHjOvztxXx9TpA5bLEv/s0VAMuCHcjA5Gz8vGn76/8gIXbmqyK//4IlIQR399cGLhifveTrGQUYh4GByffOHSRrjO7dVAVLMoFIJlXJuy8Qat89YAF6GAjAdrLxM378xS4p5MB7+cLTnwwvlk7xuvgHqpjJ5/bfEsn4U3e//np5KpqLQeHU1yKwJohOvr+Hw0oFXj1hYNVtUlkiLHxzD1gjxCsM7z9b3dix/xODwgyFUmNG9sabCDv//f/GyLVp5k8GhveHpLi8/l/c/gtqI5BSOvMtUUuclYWJidv/MVBlPVQKbOyjReVTX/xm+HedwUCc7S/z18eM4LBigMSKiH2FkAQrw1+GT++vPPaXu2f7EqwXGmXMskBPAgUuX3n/o6iUvWUqapwxsIAAKMAUl3x/FggOOajVyBSTw6OftWC3YFHx7807Zn1BkHIskgx3dzPpS+OS/Hn85y8BqEuR7YOwRap9OTBFYSJgV8M4OGgAzyeaFo+WgtoAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+rkmlX0OkwapJbSLY3ErxRTH7ruoBYD6ZH6+hre8O2WnWnhrV/EWp2S3n2eSK1sbebeIpJ3yzFipBIVEJxnksM1y8j+bK8hVVLEnCjAH0Hauy0KKzPwp8XSy2qvdLdWKxTMATHlnJxxxwGB+orqviBpyaV8JNA0YNm50e8WK8VuqyzwmfA9huIz7VyPiMLp3gPwppYDJPOs+p3C7uG8xwkZ/74i/8e964+vUvh/pcPiLwTLpMyhYItdguryURk7IFhlZizemEYD3PvVYXl94/8Pa9FbwyS6ldeILa8Ma8hUkWSJRknoGZF9siuc+IM0MnjfUbe2/497EpYRcdVgRYgfx2Z/GuZrV0zxHqmkaVqmmWNz5VrqaJHdKFBLqpJAz1HUjjsabofiHVfDV+19o969pctG0TOgByh6jBBHYfkKzSSSSTknqTSV//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABgUlEQVR4AWNgwAMYscuJ2vKs/Ildin3+lzNGrNjlGIJ+x7PgkGJgunMHYhsTFhXscov/owuLnVCECBm9FEWXY+j+VwwWY1pzHWoj2Nh8BaAoUyxUObvRlj9QJpDi/LUGSLL8+lcPFjP6pQSVA+mUYdEFknB/+TI8RpK0B7PLYF6LeP8XSfIgw2Wg2fFX3/CCBdkP/0OSZABJasosfB8AEhSVXgaVYwDZ+RTkuCqGqZ+EmIGM2D/nkCXFmIHm6P7+vY0HFGpWV5/AJEGuMPm7ioFFZvsfsFWcfrpwX4KMbWH4x6DH2gZRL8cCcw4wXBgYOJ4ChX3fQz3n/QduKkjy/yZgCEROew1UwsrAbLXpO8QIIAmU/CnAqOAhv5yB4TOzDIOs50W4HJhR9FJ0zVegy0RfqjMYwwMWqkb1nsLvHpApa7qZ77wEmoUMVP8e+R0EEij8EvDnNLIMkM366/8aUNgwML/490oJTZLpzl9fiFDU81lopjIwKHjDlGNIwSQwaQD3NWaQQfDCAgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APC9L0y71nVLbTbGLzbq5cRxpnGSaivbOfT7+4srlNlxbytFIuc4ZTgj8xTJoJbeTy5onjfAO11IOPoajr1P4H+HmufFLeJroKml6OjySysejlDjjqcAk/hVfxJ4/wBDs9WnfwdoVrG7ytJJqV/F58srk5LAPkLznt+VcNrevan4j1E3+rXbXNyVC72UDAHQAAACs2vXfAPi+18B/C/VtRt7u1m1m8vESGykfdhFxksvuC3P0psnxL8C6rE51n4eWonfBaSzZULN3OQAR+tZD+Jvhvbq72vgi7mlZtwW5vjtX2GO1cLqV1HfalcXUNrFaRSuWSCH7kY7KM+lVaKKK//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABQUlEQVR4AWNgGDjAiM1qJoggh702NlmImO/VvcyYsiwQISNVFrDBTOwecpvvwZRBJXkZPjMwsAgK6ljGcGoXA9lgAJFkcWA4wKrlYqUtwPf88PbvMJ0QVypdZj8ioMp2dffxK49//oPJQWimoD///vx5sVqPE+p4ZGnu7n//fp+PF0MWg7HZo+/++7Zejx3GR6EDX/z71sCFIgThgCzREWR8e+4/Dsmvf/6LNZeJsTKjOwfkFZNVCv8ZGV6/f/jx6uWrP1/+FhRgYNLWPnjkHygQ7MX/HZaVFBVV/e//4cPnA591tZkY+NjPAYOMgYHJkv1n2V/HSF5WaUZBwf9a/5n+vfh19PjefwxAY7kvKl62/M4iw8rnBbX088FPH97/AbmQOf/vjzoQAxOwMPy/e+PqYUwJqAi7iii6H3Cqpb0EAML8Y3fvBd7dAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+tHQ9Hutf1m20yzRnmnbaAq5x3J/Kp/E+ix+HteudLS6Fy1u2x3C4G4dR1NY9FexfArQYTfXvim6lSOLTVZVLNjDFcZ9O9eX+Ibs3/iTU7suJPOupH3jvlic1m0V6veasng/4QwaLa/Nc62fPllX+FcgY/wDHf1ryiiilLMwALEgdMnpSUV//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABF0lEQVR4AWNgIBcwomtkYvz/DyaGJsnIxsv1+ctvqCwLTBWEFrXy/rTl3EeoIBOKJKOUofGfDz9hYqiSbIaGYm8//YFJotAsiue+PDThhIuh6GRk42P9/RmhEUWShZft75df/7Hq5FTzE32z/wV2nXxquqx/viDkGJCNldBVY/r/H2EqsiSLq5/qn8+f4DYyIEsy8PCwfr53Hx6yKJKs/Gz/Di0/glWSiUeR5/flW9iNZeJT4Pp65cUvJDvhscIsbCzx6eaZt3+xSbJJ6Py7dvgjko1IDuJR0X57cvcnFEm4sQK62tvXXoWlAYjZiBD6//cTUoSAZeGSv98/efsTKehAsvAExsrH+/kTqqkISQbkNAmxkgISAJ19WdW9ZLnGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    img, lbl = dataset[i]\n",
    "    print(converting(lbl), img.size)\n",
    "    display(img.transpose(method=Image.TRANSPOSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06da4053-7a2e-4a4d-8690-0ae147ed62c1",
   "metadata": {},
   "source": [
    "# 1 version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e69c44-0f19-4f24-9647-c7084d8a914f",
   "metadata": {},
   "source": [
    "Попробуем простую модель из одного линейного слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f80b422f-27c6-49c9-94f7-f4eccd9bc823",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_dataset = EMNIST('data/', 'balanced', download=False, transform=transform)\n",
    "val_dataset = EMNIST('data/', 'balanced', download=False, train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6e1780d-e107-469e-b0cc-b4b83da5e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(nn.Module):\n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super(LogReg, self).__init__()\n",
    "        self.fc = nn.Linear(in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b3fe4cb-8f11-4ece-9399-7955cbd70c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tLoss: 2.051472\n",
      "Epoch: 1 \tLoss: 1.443084\n",
      "Epoch: 2 \tLoss: 1.331690\n",
      "Epoch: 3 \tLoss: 1.274793\n",
      "Epoch: 4 \tLoss: 1.239362\n",
      "Epoch: 5 \tLoss: 1.215182\n",
      "Epoch: 6 \tLoss: 1.195533\n",
      "Epoch: 7 \tLoss: 1.182575\n",
      "Epoch: 8 \tLoss: 1.170163\n",
      "Epoch: 9 \tLoss: 1.160444\n",
      "Val Loss: 1.199963 \tAccuracy: 0.6693085106382979\n",
      "Epoch: 10 \tLoss: 1.152815\n",
      "Epoch: 11 \tLoss: 1.145763\n",
      "Epoch: 12 \tLoss: 1.138802\n",
      "Epoch: 13 \tLoss: 1.134246\n",
      "Epoch: 14 \tLoss: 1.128831\n",
      "Epoch: 15 \tLoss: 1.123492\n",
      "Epoch: 16 \tLoss: 1.120272\n",
      "Epoch: 17 \tLoss: 1.117231\n",
      "Epoch: 18 \tLoss: 1.113529\n",
      "Epoch: 19 \tLoss: 1.110341\n",
      "Val Loss: 1.163621 \tAccuracy: 0.6823936170212765\n",
      "Epoch: 20 \tLoss: 1.107762\n",
      "Epoch: 21 \tLoss: 1.104937\n",
      "Epoch: 22 \tLoss: 1.101991\n",
      "Epoch: 23 \tLoss: 1.100299\n",
      "Epoch: 24 \tLoss: 1.098150\n",
      "Epoch: 25 \tLoss: 1.095890\n",
      "Epoch: 26 \tLoss: 1.093700\n",
      "Epoch: 27 \tLoss: 1.092410\n",
      "Epoch: 28 \tLoss: 1.091308\n",
      "Epoch: 29 \tLoss: 1.089684\n",
      "Val Loss: 1.149731 \tAccuracy: 0.6848404255319149\n",
      "Epoch: 30 \tLoss: 1.087789\n",
      "Epoch: 31 \tLoss: 1.086435\n",
      "Epoch: 32 \tLoss: 1.084968\n",
      "Epoch: 33 \tLoss: 1.084206\n",
      "Epoch: 34 \tLoss: 1.082555\n",
      "Epoch: 35 \tLoss: 1.081216\n",
      "Epoch: 36 \tLoss: 1.079970\n",
      "Epoch: 37 \tLoss: 1.078079\n",
      "Epoch: 38 \tLoss: 1.077989\n",
      "Epoch: 39 \tLoss: 1.076603\n",
      "Val Loss: 1.146864 \tAccuracy: 0.6872340425531915\n",
      "Epoch: 40 \tLoss: 1.075700\n",
      "Epoch: 41 \tLoss: 1.074386\n",
      "Epoch: 42 \tLoss: 1.074036\n",
      "Epoch: 43 \tLoss: 1.072788\n",
      "Epoch: 44 \tLoss: 1.071827\n",
      "Epoch: 45 \tLoss: 1.070893\n",
      "Epoch: 46 \tLoss: 1.069830\n",
      "Epoch: 47 \tLoss: 1.069050\n",
      "Epoch: 48 \tLoss: 1.068236\n",
      "Epoch: 49 \tLoss: 1.067792\n",
      "Val Loss: 1.142313 \tAccuracy: 0.6886702127659574\n"
     ]
    }
   ],
   "source": [
    "model = LogReg(in_features=28*28, n_classes=47)\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "\n",
    "n_epoch = 50\n",
    "val_fre = 10\n",
    "\n",
    "model.train()\n",
    "for epoch in range(n_epoch):\n",
    "    loss_sum = 0\n",
    "    for step, (data, target) in enumerate(train_loader):\n",
    "        data = data.flatten(start_dim=1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_f(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "    print(f'Epoch: {epoch} \\tLoss: {loss_sum / (step + 1):.6f}')\n",
    "\n",
    "    if (epoch+1) % val_fre == 0:\n",
    "        model.eval()\n",
    "        loss_sum = 0\n",
    "        correct = 0\n",
    "        for step, (data, target) in enumerate(val_loader):\n",
    "            data = data.flatten(start_dim=1)\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "                loss = loss_f(output, target)\n",
    "            loss_sum += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        acc = correct / len(val_loader.dataset)\n",
    "        print(f'Val Loss: {loss_sum / (step + 1):.6f} \\tAccuracy: {acc}')\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0369b02-69ad-432d-87e3-34230ae04357",
   "metadata": {},
   "source": [
    "Точность модели недостаточная"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab03767e-989a-4116-9f8d-47d2a5358c3d",
   "metadata": {},
   "source": [
    "# 2 version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d137d3-9bf4-4daa-bf7b-c3365b3894fd",
   "metadata": {},
   "source": [
    "Добавим второй линейный слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28b70751-ef76-44b5-8722-34308e16242a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=45, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=45, out_features=47, bias=True)\n",
      ")\n",
      "Epoch: 0 \tLoss: 2.607973\n",
      "Val Loss: 1.720239 \tAccuracy: 0.5463829787234042\n",
      "Epoch: 1 \tLoss: 1.507018\n",
      "Epoch: 2 \tLoss: 1.322468\n",
      "Epoch: 3 \tLoss: 1.242596\n",
      "Epoch: 4 \tLoss: 1.188235\n",
      "Epoch: 5 \tLoss: 1.144420\n",
      "Epoch: 6 \tLoss: 1.107208\n",
      "Epoch: 7 \tLoss: 1.072965\n",
      "Epoch: 8 \tLoss: 1.040199\n",
      "Epoch: 9 \tLoss: 1.011349\n",
      "Epoch: 10 \tLoss: 0.981901\n",
      "Val Loss: 1.005871 \tAccuracy: 0.7139893617021277\n",
      "Epoch: 11 \tLoss: 0.956062\n",
      "Epoch: 12 \tLoss: 0.929783\n",
      "Epoch: 13 \tLoss: 0.908262\n",
      "Epoch: 14 \tLoss: 0.885797\n",
      "Epoch: 15 \tLoss: 0.864728\n",
      "Epoch: 16 \tLoss: 0.847744\n",
      "Epoch: 17 \tLoss: 0.829077\n",
      "Epoch: 18 \tLoss: 0.815442\n",
      "Epoch: 19 \tLoss: 0.800696\n",
      "Val Loss: 0.850914 \tAccuracy: 0.7526595744680851\n"
     ]
    }
   ],
   "source": [
    "def train(model, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre):\n",
    "    model.train()\n",
    "    for epoch in range(n_epoch):\n",
    "        loss_sum = 0\n",
    "        for step, (data, target) in enumerate(train_loader):\n",
    "            data = data.flatten(start_dim=1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_f(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "        print(f'Epoch: {epoch} \\tLoss: {loss_sum / (step + 1):.6f}')\n",
    "\n",
    "        if epoch % val_fre == 0:\n",
    "            validate(model, val_loader)\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    for step, (data, target) in enumerate(val_loader):\n",
    "        data = data.flatten(start_dim=1)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "            loss = loss_f(output, target)\n",
    "        loss_sum += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    acc = correct / len(val_loader.dataset)\n",
    "    print(f'Val Loss: {loss_sum / (step + 1):.6f} \\tAccuracy: {acc}')\n",
    "    model.train()\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hid_features, n_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hid_features)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hid_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model_mlp = MLP(in_features=28*28, hid_features=2^47, n_classes=47)\n",
    "print(model_mlp)\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_mlp.parameters(), lr=1e-1)\n",
    "\n",
    "n_epoch = 20\n",
    "val_fre = 10\n",
    "\n",
    "train(model_mlp, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre)\n",
    "validate(model_mlp, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c019a14c-609a-4d41-8107-a513370f4274",
   "metadata": {},
   "source": [
    "Результат получился значительно лучше, но цель недостигнута"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e15285-a59c-4a6e-9e9b-431fa0695ad8",
   "metadata": {},
   "source": [
    "# 3 version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297868af-6ff7-4835-9861-429291bb8207",
   "metadata": {},
   "source": [
    "Добавим сверточные слои"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2d062de5-11ee-4eb6-b5a9-d35d83a39369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=3136, out_features=45, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=45, out_features=47, bias=True)\n",
      ")\n",
      "Epoch: 0 \tLoss: 3.584606\n",
      "Val Loss: 2.711091 \tAccuracy: 0.2873404255319149\n",
      "Epoch: 1 \tLoss: 1.930190\n",
      "Epoch: 2 \tLoss: 1.455408\n",
      "Epoch: 3 \tLoss: 1.314292\n",
      "Epoch: 4 \tLoss: 1.228303\n",
      "Epoch: 5 \tLoss: 1.162551\n",
      "Epoch: 6 \tLoss: 1.109569\n",
      "Epoch: 7 \tLoss: 1.067838\n",
      "Epoch: 8 \tLoss: 1.040284\n",
      "Epoch: 9 \tLoss: 1.000452\n",
      "Epoch: 10 \tLoss: 0.971190\n",
      "Val Loss: 0.976999 \tAccuracy: 0.7079255319148936\n",
      "Epoch: 11 \tLoss: 0.942609\n",
      "Epoch: 12 \tLoss: 0.924762\n",
      "Epoch: 13 \tLoss: 0.912016\n",
      "Epoch: 14 \tLoss: 0.887587\n",
      "Epoch: 15 \tLoss: 0.871460\n",
      "Epoch: 16 \tLoss: 0.857944\n",
      "Epoch: 17 \tLoss: 0.847320\n",
      "Epoch: 18 \tLoss: 0.839078\n",
      "Epoch: 19 \tLoss: 0.828477\n",
      "Val Loss: 0.869244 \tAccuracy: 0.7370212765957447\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train(model, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre):\n",
    "    model.train()\n",
    "    for epoch in range(n_epoch):\n",
    "        loss_sum = 0\n",
    "        for step, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data).squeeze(1)\n",
    "            \n",
    "            loss = loss_f(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "        print(f'Epoch: {epoch} \\tLoss: {loss_sum / (step + 1):.6f}')\n",
    "\n",
    "        if epoch % val_fre == 0:\n",
    "            validate(model, val_loader)\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    for step, (data, target) in enumerate(val_loader):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(data).squeeze(1)\n",
    "            loss = loss_f(output, target)\n",
    "        loss_sum += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    acc = correct / len(val_loader.dataset)\n",
    "    print(f'Val Loss: {loss_sum / (step + 1):.6f} \\tAccuracy: {acc}')\n",
    "    model.train()\n",
    "\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, hid_features, n_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64*7*7, hid_features)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(hid_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "       \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, 2)   \n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model_mlp = MLP( hid_features=2^47, n_classes=47)\n",
    "print(model_mlp)\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_mlp.parameters(), lr=1e-1)\n",
    "\n",
    "n_epoch = 20\n",
    "val_fre = 10\n",
    "\n",
    "train(model_mlp, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre)\n",
    "validate(model_mlp, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e1fa13-da23-4cf3-a438-972a38b57044",
   "metadata": {},
   "source": [
    "Результат улучшить не удалось"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d511f64b-9add-4375-b5f3-2d8a6275f7e4",
   "metadata": {},
   "source": [
    "# 4 Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff99505-5233-45db-adfe-58c3897ec6da",
   "metadata": {},
   "source": [
    "Добавим батч-нормализацию и макспулинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b2cdfae9-bfec-44f9-bf43-03f8179cb7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=2304, out_features=3000, bias=True)\n",
      "  (drop): Dropout2d(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=3000, out_features=600, bias=True)\n",
      "  (fc3): Linear(in_features=600, out_features=47, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msi-1\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tLoss: 1.162711\n",
      "Val Loss: 0.654232 \tAccuracy: 0.7924468085106383\n",
      "Epoch: 1 \tLoss: 0.560543\n",
      "Epoch: 2 \tLoss: 0.488813\n",
      "Epoch: 3 \tLoss: 0.454339\n",
      "Epoch: 4 \tLoss: 0.436435\n",
      "Epoch: 5 \tLoss: 0.412805\n",
      "Epoch: 6 \tLoss: 0.396634\n",
      "Epoch: 7 \tLoss: 0.382840\n",
      "Epoch: 8 \tLoss: 0.372654\n",
      "Epoch: 9 \tLoss: 0.365446\n",
      "Epoch: 10 \tLoss: 0.355684\n",
      "Val Loss: 0.408625 \tAccuracy: 0.8633510638297872\n",
      "Epoch: 11 \tLoss: 0.347033\n",
      "Epoch: 12 \tLoss: 0.340145\n",
      "Epoch: 13 \tLoss: 0.334208\n",
      "Epoch: 14 \tLoss: 0.326531\n",
      "Epoch: 15 \tLoss: 0.321561\n",
      "Epoch: 16 \tLoss: 0.315878\n",
      "Epoch: 17 \tLoss: 0.307617\n",
      "Epoch: 18 \tLoss: 0.305559\n",
      "Epoch: 19 \tLoss: 0.298119\n",
      "Val Loss: 0.378924 \tAccuracy: 0.8720212765957447\n"
     ]
    }
   ],
   "source": [
    "def train(model, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre):\n",
    "    model.train()\n",
    "    for epoch in range(n_epoch):\n",
    "        loss_sum = 0\n",
    "        for step, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data).squeeze(1)\n",
    "            \n",
    "            loss = loss_f(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "        print(f'Epoch: {epoch} \\tLoss: {loss_sum / (step + 1):.6f}')\n",
    "\n",
    "        if epoch % val_fre == 0:\n",
    "            validate(model, val_loader)\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    for step, (data, target) in enumerate(val_loader):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(data).squeeze(1)\n",
    "            loss = loss_f(output, target)\n",
    "        loss_sum += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    acc = correct / len(val_loader.dataset)\n",
    "    print(f'Val Loss: {loss_sum / (step + 1):.6f} \\tAccuracy: {acc}')\n",
    "    model.train()\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=3000)\n",
    "        self.drop = nn.Dropout2d(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=3000, out_features=600)\n",
    "        self.fc3 = nn.Linear(in_features=600, out_features=47)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "model_mlp = MLP()\n",
    "print(model_mlp)\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_mlp.parameters(), lr=1e-1)\n",
    "\n",
    "n_epoch = 20\n",
    "val_fre = 10\n",
    "\n",
    "train(model_mlp, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre)\n",
    "validate(model_mlp, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba13c6de-bd52-4537-9d30-41aab80ae848",
   "metadata": {},
   "source": [
    "Результат достиг пороговой отметки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59421d64-a1e9-4e60-9f0e-e794fcc6bb76",
   "metadata": {},
   "source": [
    "# 5 Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52c28bd-938a-4e44-9408-87403531d124",
   "metadata": {},
   "source": [
    "Добавим еще один сверточный слой и поэкспериментируем с промежуточными фичами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "5d4d54f5-8ef5-4891-9384-3f96aa897374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMM(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=512, out_features=6000, bias=True)\n",
      "  (drop): Dropout2d(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=6000, out_features=1200, bias=True)\n",
      "  (fc3): Linear(in_features=1200, out_features=400, bias=True)\n",
      "  (fc4): Linear(in_features=400, out_features=47, bias=True)\n",
      ")\n",
      "Epoch: 0 \tLoss: 1.211187\n",
      "Val Loss: 0.628291 \tAccuracy: 0.8000531914893617\n",
      "Epoch: 1 \tLoss: 0.500560\n",
      "Epoch: 2 \tLoss: 0.429143\n",
      "Epoch: 3 \tLoss: 0.391186\n",
      "Epoch: 4 \tLoss: 0.366413\n",
      "Epoch: 5 \tLoss: 0.346320\n",
      "Epoch: 6 \tLoss: 0.331714\n",
      "Epoch: 7 \tLoss: 0.319878\n",
      "Epoch: 8 \tLoss: 0.307481\n",
      "Epoch: 9 \tLoss: 0.299149\n",
      "Epoch: 10 \tLoss: 0.287886\n",
      "Val Loss: 0.391774 \tAccuracy: 0.8676063829787234\n",
      "Epoch: 11 \tLoss: 0.281094\n",
      "Epoch: 12 \tLoss: 0.272777\n",
      "Epoch: 13 \tLoss: 0.266283\n",
      "Epoch: 14 \tLoss: 0.257570\n",
      "Epoch: 15 \tLoss: 0.251372\n",
      "Epoch: 16 \tLoss: 0.244200\n",
      "Epoch: 17 \tLoss: 0.240185\n",
      "Epoch: 18 \tLoss: 0.235766\n",
      "Epoch: 19 \tLoss: 0.229215\n",
      "Val Loss: 0.366040 \tAccuracy: 0.8777127659574468\n"
     ]
    }
   ],
   "source": [
    "def train(model, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre):\n",
    "    model.train()\n",
    "    for epoch in range(n_epoch):\n",
    "        loss_sum = 0\n",
    "        for step, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data).squeeze(1)\n",
    "            \n",
    "            loss = loss_f(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "        print(f'Epoch: {epoch} \\tLoss: {loss_sum / (step + 1):.6f}')\n",
    "\n",
    "        if epoch % val_fre == 0:\n",
    "            validate(model, val_loader)\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    for step, (data, target) in enumerate(val_loader):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(data).squeeze(1)\n",
    "            loss = loss_f(output, target)\n",
    "        loss_sum += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    acc = correct / len(val_loader.dataset)\n",
    "    print(f'Val Loss: {loss_sum / (step + 1):.6f} \\tAccuracy: {acc}')\n",
    "    model.train()\n",
    "\n",
    "class MMM(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MMM, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=128*2*2, out_features=6000)\n",
    "        self.drop = nn.Dropout2d(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=6000, out_features=1200)\n",
    "        self.fc3 = nn.Linear(in_features=1200, out_features=400)\n",
    "        self.fc4 = nn.Linear(in_features=400, out_features=47)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "       \n",
    "        out = out.view(out.size(0), -1)\n",
    "       \n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.fc4(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "model_mmm = MMM()\n",
    "print(model_mmm)\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer_mmm = torch.optim.SGD(model_mmm.parameters(), lr=1e-1)\n",
    "\n",
    "n_epoch = 20\n",
    "val_fre = 10\n",
    "\n",
    "train(model_mmm, optimizer_mmm, loss_f, train_loader, val_loader, n_epoch, val_fre)\n",
    "validate(model_mmm, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505ed0d-574c-4b4b-b140-2ffe3e8ad410",
   "metadata": {},
   "source": [
    "Результат значительно улучшить не удалось, но метрика все еще выше порога - оставляем такой вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "453792ab-23c2-40bd-ac72-48c84ab78da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(model_mmm.state_dict(), 'cnn.ckpt')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
